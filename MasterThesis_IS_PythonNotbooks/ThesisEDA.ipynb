{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import CubicSpline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/finalannotation.xlsx\")\n",
    "df1 = pd.read_excel(\"data/finalannotation+poststats.xlsx\")\n",
    "df2 = pd.read_excel(\"data/finalannotation+poststats+date.xlsx\")\n",
    "fulldf = pd.read_csv(\"data/finalwbdataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16653d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"new class type\", \"new ethical issues\", \"Unnamed: 17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related = df[df[\"stance comment\"] != \"3. unrelated to whistleblowing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = df1.drop_duplicates(\"Post_ID\")\n",
    "len(df_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts[\"ethical issue label post 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts[\"ethical issue label post 2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ethical issue label comment 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fe543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ethical issue label comment 2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stance post\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts[\"stance post\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6516b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Score\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c17707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lowscore = df[df[\"Score\"] < 0]\n",
    "df_highscore = df[df[\"Score\"] > 0]\n",
    "df_unrelated = df[df[\"stance comment\"] == \"3. unrelated to whistleblowing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74583c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lowscore[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highscore[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_highscore[\"stance comment\"].value_counts():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highscore[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_unrelated[df_unrelated[\"Score\"] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f76b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df_lowscore[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355590c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in series.index:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_lowscore[\"stance comment\"].value_counts(normalize = True).items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "related = df[df[\"stance comment\"] != \"3. unrelated to whistleblowing\"]\n",
    "related_lowscore = related[related[\"Score\"] < 0]\n",
    "related_highscore = related[related[\"Score\"] > 0]\n",
    "related_lowscore[\"stance comment\"].value_counts(normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_highscore[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns = [\"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "df2.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-wilderness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fulldf.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf_post = fulldf.drop_duplicates(\"Post_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf_post[\"Subreddit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postscores = pd.read_excel(\"all_posts_withdate_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postscores = df_postscores.sort_values(by = \"post_score\", ascending = False)\n",
    "df_postscores_high = df_postscores[df_postscores[\"post_score\"] >= 10000]\n",
    "df_postscores_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf_post[\"Post_ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df2['post_date'][0:3]:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date column to datetime format\n",
    "df2['post_date'] = pd.to_datetime(df2['post_date'], format='%d-%m-%Y')\n",
    "\n",
    "def get_year_quarter(date):\n",
    "    quarter = (date.month - 1) // 3 + 1\n",
    "    return f\"{date.year} Q{quarter}\"\n",
    "\n",
    "#df2['year_quarter'] = df2['post_date'].apply(get_year_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['post_date'] = pd.to_datetime(df2['post_date'], format='%d-%m-%Y')\n",
    "\n",
    "def get_year(date):\n",
    "    return f\"{date.year}\"\n",
    "\n",
    "#create new column with function\n",
    "df2['year'] = df2['post_date'].apply(get_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_posts = df2.drop_duplicates(\"Post_ID\")\n",
    "df2_posts = df2_posts.drop(columns = [\"Unnamed: 0\", \"Unnamed: 0.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_posts[\"year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_posts.sort_values(by = [\"year\"], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_retal = df2_posts[(df2_posts[\"ethical issue label post 1\"] == \"9. whistleblower retaliation\") | (df2_posts[\"ethical issue label post 2\"] == \"9. whistleblower retaliation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_privacy = df2_posts[(df2_posts[\"ethical issue label post 1\"] == \"0. privacy\") | (df2_posts[\"ethical issue label post 2\"] == \"0. privacy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_manip = df2_posts[(df2_posts[\"ethical issue label post 1\"] == \"5. manipulation\") | (df2_posts[\"ethical issue label post 2\"] == \"5. manipulation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_disc = df2_posts[(df2_posts[\"ethical issue label post 1\"] == \"3. discrimination\") | (df2_posts[\"ethical issue label post 2\"] == \"3. discrimination\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_safety = df2_posts[(df2_posts[\"ethical issue label post 1\"] == \"7. safety\") | (df2_posts[\"ethical issue label post 2\"] == \"7. safety\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_retal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_retal = df2posts_retal.drop(columns = ['Post_Title', 'Post_URL', 'Comment_ID', 'Post_Score',\n",
    "       'Num_Comments', 'Body', 'Score','Subreddit',\n",
    "       'type label post', 'stance post', 'type label comment',\n",
    "       'ethical issue label comment 1', 'ethical issue label comment 2',\n",
    "       'stance comment'])\n",
    "\n",
    "\n",
    "df2posts_retal['year sum'] = df2posts_retal.groupby('year')['year'].transform('size')\n",
    "\n",
    "df2posts_retal = df2posts_retal.drop_duplicates(\"year\")\n",
    "df2posts_retal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "retallist = df2posts_retal[[\"year\", \"year sum\"]].sort_values(by = \"year\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_privacy = df2posts_privacy.drop(columns = ['Post_Title', 'Post_URL', 'Comment_ID', 'Post_Score',\n",
    "       'Num_Comments', 'Body', 'Score','Subreddit',\n",
    "       'type label post', 'stance post', 'type label comment',\n",
    "       'ethical issue label comment 1', 'ethical issue label comment 2',\n",
    "       'stance comment'])\n",
    "\n",
    "\n",
    "df2posts_privacy['year sum'] = df2posts_privacy.groupby('year')['year'].transform('size')\n",
    "\n",
    "df2posts_privacy = df2posts_privacy.drop_duplicates(\"year\")\n",
    "df2posts_privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "privlist = df2posts_privacy[[\"year\", \"year sum\"]].sort_values(by = \"year\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_manip = df2posts_manip.drop(columns = ['Post_Title', 'Post_URL', 'Comment_ID', 'Post_Score',\n",
    "       'Num_Comments', 'Body', 'Score','Subreddit',\n",
    "       'type label post', 'stance post', 'type label comment',\n",
    "       'ethical issue label comment 1', 'ethical issue label comment 2',\n",
    "       'stance comment'])\n",
    "\n",
    "\n",
    "df2posts_manip['year sum'] = df2posts_manip.groupby('year')['year'].transform('size')\n",
    "\n",
    "df2posts_manip = df2posts_manip.drop_duplicates(\"year\")\n",
    "df2posts_manip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "maniplist = df2posts_manip[[\"year\", \"year sum\"]].sort_values(by = \"year\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_disc = df2posts_disc.drop(columns = ['Post_Title', 'Post_URL', 'Comment_ID', 'Post_Score',\n",
    "       'Num_Comments', 'Body', 'Score','Subreddit',\n",
    "       'type label post', 'stance post', 'type label comment',\n",
    "       'ethical issue label comment 1', 'ethical issue label comment 2',\n",
    "       'stance comment'])\n",
    "\n",
    "\n",
    "df2posts_disc['year sum'] = df2posts_disc.groupby('year')['year'].transform('size')\n",
    "\n",
    "df2posts_disc = df2posts_disc.drop_duplicates(\"year\")\n",
    "df2posts_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "disclist = df2posts_disc[[\"year\", \"year sum\"]].sort_values(by = \"year\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2posts_safety = df2posts_safety.drop(columns = ['Post_Title', 'Post_URL', 'Comment_ID', 'Post_Score',\n",
    "       'Num_Comments', 'Body', 'Score','Subreddit',\n",
    "       'type label post', 'stance post', 'type label comment',\n",
    "       'ethical issue label comment 1', 'ethical issue label comment 2',\n",
    "       'stance comment'])\n",
    "\n",
    "\n",
    "df2posts_safety['year sum'] = df2posts_safety.groupby('year')['year'].transform('size') #count the years\n",
    "\n",
    "df2posts_safety = df2posts_safety.drop_duplicates(\"year\")\n",
    "df2posts_safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "safelist = df2posts_safety[[\"year\", \"year sum\"]].sort_values(by = \"year\", ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "safelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "\n",
    "x_values_int = np.arange(len(x_values))\n",
    "priv_values = np.array([3, 5, 5, 12, 1, 11, 12, 2, 7, 5, 1, 0])\n",
    "manip_values = np.array([1, 2, 0, 1, 0, 13, 6, 7, 9, 12, 1, 1])\n",
    "retal_values = np.array([2, 0, 1, 9, 1, 1, 2, 4, 4, 1, 0, 7])\n",
    "disc_values = np.array([0, 1, 0, 0, 0, 3, 1, 1, 4, 11, 1, 2])\n",
    "safe_values = np.array([0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 3, 9])\n",
    "\n",
    "marker_values = np.array([3, 5, 5, 12, 1, 13, 12, 7, 9, 12, 3, 9])\n",
    "\n",
    "#colors for the markers corresponding to the line color\n",
    "colors = [\"#49b3fe\", \"#49b3fe\", \"#49b3fe\", \"#49b3fe\", \"#b2df8a\", \"#fb9a99\", \"#49b3fe\", \"#fb9a99\", \"#fb9a99\", \"#fb9a99\", \"#1f78b4\", \"#1f78b4\"]\n",
    "\n",
    "#function that changes the lines to smoother splines\n",
    "def smooth_line(x, y):\n",
    "    cs = CubicSpline(x, y, bc_type='natural')\n",
    "    x_new = np.linspace(x.min(), x.max(), 300) #change this number to change the appearance of the splines\n",
    "    y_new = cs(x_new)\n",
    "    y_new = np.clip(y_new, y.min(), y.max()) #cut off the lines to fit the data better, unfortunately not 100% accurate\n",
    "    return x_new, y_new\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "#apply the smoothness function to every line, write labels, colors, insert fill color\n",
    "for y_values, label, color in zip(\n",
    "    [priv_values, manip_values, retal_values, disc_values, safe_values],\n",
    "    ['Privacy', 'Manip.', 'Retal.', 'Discrim.', 'Safety'],\n",
    "    ['#49b3fe', '#fb9a99', '#b2df8a', '#33a02c', '#1f78b4']\n",
    "):\n",
    "\n",
    "    x_new, y_new = smooth_line(x_values_int, y_values)\n",
    "    \n",
    "    plt.plot(x_new, y_new, label=label, color=color)\n",
    "    \n",
    "    plt.fill_between(x_new, y_new, alpha=0.2, color=color)  #change alpha for opacity\n",
    "\n",
    "#plot markers using the marker_values list and their colors\n",
    "for i, (marker_val, color) in enumerate(zip(marker_values, colors)):\n",
    "    plt.scatter(x_values_int[i], marker_val, color=color, edgecolor='black', s=100, zorder=5)  # Marker\n",
    "\n",
    "\n",
    "plt.title(\"Title\")\n",
    "plt.xlabel(\"Year Posted\", fontsize = 20)\n",
    "plt.ylabel(\"Ethical Issue Count\", fontsize = 20)\n",
    "\n",
    "all_y_ticks = np.arange(0, np.max(marker_values) + 1, 1)\n",
    "plt.yticks(ticks=all_y_ticks, fontsize = 20)\n",
    "\n",
    "\n",
    "plt.xticks(ticks=x_values_int, labels=x_values, fontsize = 16)\n",
    "\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "\n",
    "plt.legend(fontsize = 18)\n",
    "\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts = pd.read_excel(\"all_posts_withdate1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts['Post_Date'] = pd.to_datetime(df_allposts['Post_Date'], format='%d-%m-%Y')\n",
    "\n",
    "df_allposts['Year'] = df_allposts['Post_Date'].apply(get_year)\n",
    "\n",
    "df_allposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts_score = pd.read_excel(\"all_posts_withdate_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts[\"Post_Score\"] = df_allposts_score[\"post_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_allposts[\"Num_Comments\"].max(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_allposts[\"Post_Score\"].max(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts['year sum'] = df_allposts.groupby('Year')['Year'].transform('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts_yearsum = df_allposts.drop_duplicates(\"Year\")\n",
    "df_allposts_yearsum = df_allposts_yearsum.sort_values(by = \"Year\", ascending = True)\n",
    "df_allposts_yearsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts_yearsum[\"year sum\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts[\"Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts_2010 = df_allposts[df_allposts[\"Year\"] == \"2010\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allposts_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf_post[fulldf_post[\"Post_ID\"] == \"ebaal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"2010\", \"2011\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \n",
    "          \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\", \"Mean Num\"]\n",
    "x_list = [3, 2, 11, 10, 11, 22, 2, 37, 25, 18, 38, 41, 11, 18, 18]\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe',\n",
    "         '#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe', '#025d9d']\n",
    "\n",
    "\n",
    "bars = plt.bar(labels, x_list, color=colors)\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, str(height), ha='center', va='bottom', fontsize = 18)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Title\")\n",
    "plt.xlabel(\"Years\", fontsize = 18)\n",
    "plt.ylabel(\"Number of Posts\", fontsize = 18)\n",
    "plt.yticks(fontsize = 18)\n",
    "plt.xticks(rotation=20, fontsize = 18)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shades of blue from https://html-color.codes/\n",
    "colors = ['#1f77b4', '#3498db', '#2980b9', '#5499c7', '#5dade2', '#85c1e9', '#aed6f1']\n",
    "\n",
    "#show colors on barchart\n",
    "plt.figure(figsize=(8, 4))\n",
    "for i, color in enumerate(colors):\n",
    "    plt.bar(i, i, color=color)\n",
    "\n",
    "plt.title('Matplotlib Color Scheme with Shades of Blue')\n",
    "plt.xticks(range(len(colors)), [f'Shade {i+1}' for i in range(len(colors))])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your existing DataFrame\n",
    "# df = pd.read_csv('your_file.csv') # if you are reading from a CSV file\n",
    "\n",
    "# Define shades of blue\n",
    "colors = ['#025d9d', '#49b3fe', '#025d9d', '#49b3fe']\n",
    "\n",
    "# Map categorical values to colors\n",
    "unique_stances = sorted(df['stance comment'].unique())\n",
    "color_map = {stance: colors[i % len(colors)] for i, stance in enumerate(unique_stances)}\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for stance in unique_stances:\n",
    "    subset = df[df['stance comment'] == stance]\n",
    "    plt.scatter([stance]*len(subset), subset['Score'], color=color_map[stance], label=stance)\n",
    "\n",
    "plt.xlabel('Stance')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Stance')\n",
    "plt.title('Scatter plot of Scores and Stances (Comments)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#025d9d', '#49b3fe', '#025d9d', '#49b3fe']\n",
    "\n",
    "#assign categorical values to colors\n",
    "unique_stances_post = sorted(df_posts['stance post'].unique())\n",
    "color_map = {stance: colors[i % len(colors)] for i, stance in enumerate(unique_stances_post)}\n",
    "\n",
    "#plot the scatter plot\n",
    "plt.figure(figsize=(20, 12))\n",
    "for stance in unique_stances_post:\n",
    "    subset = df_posts[df_posts['stance post'] == stance]\n",
    "    plt.scatter([stance]*len(subset), subset['Post_Score'], color=color_map[stance], label=stance)\n",
    "\n",
    "plt.xlabel('Stance')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Stance')\n",
    "plt.title('Scatter plot of Post Score and Stance (Post)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts[\"stance post\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "\n",
    "for i in df_posts[\"stance post\"].value_counts():\n",
    "    x_list.append(i)\n",
    "\n",
    "x = sorted(x_list)\n",
    "labels = ['Against WB', 'Unrelated', 'Neutral', 'For WB']\n",
    "\n",
    "#plot the bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=['#025d9d', '#49b3fe', '#025d9d', '#49b3fe'])\n",
    "\n",
    "#add the values on the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title('Stance distribution of lowscoring comments')\n",
    "plt.xlabel('Stances')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#plt.savefig(\"results/BarStanceLowscoreComments.jpg\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "\n",
    "for i in df[\"stance comment\"].value_counts():\n",
    "    x_list.append(i)\n",
    "\n",
    "x = sorted(x_list)\n",
    "labels = ['Neutral', 'Against WB', 'For WB', 'Unrelated']\n",
    "\n",
    "#bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=['#025d9d', '#49b3fe', '#025d9d', '#49b3fe'])\n",
    "\n",
    "#value labels on the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title('Stance distribution of lowscoring comments')\n",
    "plt.xlabel('Stances')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#plt.savefig(\"results/BarStanceLowscoreComments.jpg\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "\n",
    "for i in df_lowscore[\"stance comment\"].value_counts():\n",
    "    x_list.append(i)\n",
    "\n",
    "x = sorted(x_list)\n",
    "labels = ['Neutral', 'For WB', 'Against WB', 'Unrelated']\n",
    "\n",
    "#bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=['#025d9d', '#49b3fe', '#025d9d', '#49b3fe'])\n",
    "\n",
    "#value labels on the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title('Stance distribution of lowscoring comments')\n",
    "plt.xlabel('Stances')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#plt.savefig(\"results/BarStanceLowscoreComments.jpg\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605fa8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "\n",
    "for i in df_lowscore[\"stance comment\"].value_counts():\n",
    "    x_list.append(i)\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "x_list.pop()\n",
    "\n",
    "x = x_list\n",
    "labels = ['Neutral', 'For WB', 'Against WB']\n",
    "\n",
    "#bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=['#025d9d', '#49b3fe', '#025d9d', '#49b3fe'])\n",
    "\n",
    "#value labels on the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title('Stance distribution of lowscoring comments (without unrelated)')\n",
    "plt.xlabel('Stances')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "for i in df_highscore[\"stance comment\"].value_counts():\n",
    "    x_list.append(i)\n",
    "    \n",
    "\n",
    "x = sorted(x_list)\n",
    "labels = ['Against WB', 'Neutral', 'For WB', 'Unrelated']\n",
    "\n",
    "#bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=['#025d9d', '#49b3fe', '#025d9d', '#49b3fe'])\n",
    "\n",
    "#value labels on the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "    \n",
    "\n",
    "plt.title('Stance distribution of highscoring comments')\n",
    "plt.xlabel('Stances')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "\n",
    "for i in df_highscore[\"stance comment\"].value_counts():\n",
    "    x_list.append(i)\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "x_list.pop()\n",
    "\n",
    "x = x_list\n",
    "labels = ['Neutral', 'Against WB', 'For WB']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=['#025d9d', '#49b3fe', '#025d9d', '#49b3fe'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.title('Stance distribution of highscoring comments (without unrelated)')\n",
    "plt.xlabel('Stances')\n",
    "plt.ylabel('Count')\n",
    "    \n",
    "plt.savefig(\"results/BarStanceHighscoreCommentsRelated.jpg\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df[\"stance comment\"] == \"0. for whistleblowing\"]\n",
    "df_1 = df[df[\"stance comment\"] == \"1. against whistleblowing\"]\n",
    "df_2 = df[df[\"stance comment\"] == \"2. neutral\"]\n",
    "df_3 = df[df[\"stance comment\"] == \"3. unrelated to whistleblowing\"]\n",
    "\n",
    "dflist = [df_0, df_1, df_2]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Score\"].mean())\n",
    "    \n",
    "x_list.append(df_related[\"Score\"].mean())\n",
    "\n",
    "sorted(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Score\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df[\"stance comment\"] == \"0. for whistleblowing\"]\n",
    "df_1 = df[df[\"stance comment\"] == \"1. against whistleblowing\"]\n",
    "df_2 = df[df[\"stance comment\"] == \"2. neutral\"]\n",
    "df_3 = df[df[\"stance comment\"] == \"3. unrelated to whistleblowing\"]\n",
    "\n",
    "dflist = [df_0, df_1, df_2]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Score\"].mean())\n",
    "    \n",
    "x_list.append(df_related[\"Score\"].mean())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"Against Whistleblowing\", \"Neutral\", \"Mean Score\", \"For Whistleblowing\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "#horizontal bar plot\n",
    "bars = plt.barh(labels, x, color=[\"#49b3fe\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "#text labels inside or outside the bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    height = bar.get_height()\n",
    "    \n",
    "    if i == 0:  #for the fourth bar (index 3)\n",
    "        #place text outside of the bar\n",
    "        plt.text(\n",
    "            width + 0.1 * width,  #slightly to the right of the bar\n",
    "            bar.get_y() + height / 2.0,\n",
    "            \"%d\" % int(width),\n",
    "            ha=\"left\",  \n",
    "            va=\"center\",\n",
    "            fontsize=20,\n",
    "            color='black'\n",
    "        )\n",
    "    else:\n",
    "        #place text inside the bar\n",
    "        plt.text(\n",
    "            width * 0.98,  # 95% of the bar width for positioning text inside\n",
    "            bar.get_y() + height / 2.0,\n",
    "            \"%d\" % int(width),\n",
    "            ha=\"right\", \n",
    "            va=\"center\",\n",
    "            fontsize=20,\n",
    "            color='white'\n",
    "        )\n",
    "\n",
    "plt.xlabel(\"Score\", fontsize = 20)\n",
    "plt.xticks(fontsize = 18)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.ylabel(\"Comment Stances\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_post = df_posts[df_posts[\"stance post\"] == \"0. for whistleblowing\"]\n",
    "df_1_post = df_posts[df_posts[\"stance post\"] == \"1. against whistleblowing\"]\n",
    "df_2_post = df_posts[df_posts[\"stance post\"] == \"2. neutral\"]\n",
    "\n",
    "dflist = [df_0_post, df_1_post, df_2_post]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Post_Score\"].mean())\n",
    "    \n",
    "x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_post = df_posts[df_posts[\"stance post\"] == \"0. for whistleblowing\"]\n",
    "df_1_post = df_posts[df_posts[\"stance post\"] == \"1. against whistleblowing\"]\n",
    "df_2_post = df_posts[df_posts[\"stance post\"] == \"2. neutral\"]\n",
    "\n",
    "dflist = [df_0_post, df_1_post, df_2_post]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Post_Score\"].mean())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"Against Whistleblowing\", \"For Whistleblowing\", \"Neutral\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=[\"#025d9d\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%d\" % int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title(\"Mean Scores For Stances (Post)\")\n",
    "plt.xlabel(\"Stances\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0, df_1, df_2]\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for i in dflist:\n",
    "    temp_list.append(i[\"Score\"].max())\n",
    "    \n",
    "temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0, df_1, df_2]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Score\"].max())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"Against Whistleblowing\", \"Neutral\", \"For Whistleblowing\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=[\"#025d9d\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%d\" % int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title(\"Maximum Scores For Stances (Comments)\")\n",
    "plt.xlabel(\"Stances\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0, df_1, df_2]\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for i in dflist:\n",
    "    temp_list.append(i[\"Score\"].min())\n",
    "    \n",
    "temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0, df_1, df_2]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Score\"].min())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"Against Whistleblowing\", \"For Whistleblowing\", \"Neutral\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=[\"#025d9d\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%d\" % int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title(\"Minimum Scores For Stances (Comments)\")\n",
    "plt.xlabel(\"Stances\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_post = df_posts[df_posts[\"stance post\"] == \"0. for whistleblowing\"]\n",
    "df_1_post = df_posts[df_posts[\"stance post\"] == \"1. against whistleblowing\"]\n",
    "df_2_post = df_posts[df_posts[\"stance post\"] == \"2. neutral\"]\n",
    "\n",
    "dflist = [df_0_post, df_1_post, df_2_post]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Num_Comments\"].min())\n",
    "    \n",
    "x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0_post, df_1_post, df_2_post]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Num_Comments\"].mean())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"Against Whistleblowing\", \"For Whistleblowing\", \"Neutral\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=[\"#025d9d\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%d\" % int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title(\"Mean Num Comments For Stances (Post)\")\n",
    "plt.xlabel(\"Stances\")\n",
    "plt.ylabel(\"Num Comments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0_post, df_1_post, df_2_post]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Num_Comments\"].max())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"Against Whistleblowing\", \"Neutral\", \"For Whistleblowing\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=[\"#025d9d\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%d\" % int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title(\"Maximum Num Comments For Stances (Post)\")\n",
    "plt.xlabel(\"Stances\")\n",
    "plt.ylabel(\"Num Comments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = [df_0_post, df_1_post, df_2_post]\n",
    "x_list = []\n",
    "\n",
    "\n",
    "for i in dflist:\n",
    "    x_list.append(i[\"Num_Comments\"].min())\n",
    "\n",
    "x_list = sorted(x_list)\n",
    "\n",
    "x = x_list\n",
    "labels = [\"For Whistleblowing\", \"Neutral\", \"Against Whistleblowing\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, x, color=[\"#025d9d\", \"#49b3fe\", \"#025d9d\", \"#49b3fe\"])\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%d\" % int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "\n",
    "plt.title(\"Minimum Num Comments For Stances (Post)\")\n",
    "plt.xlabel(\"Stances\")\n",
    "plt.ylabel(\"Num Comments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_0_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_dict1_post = df_posts[\"ethical issue label post 1\"].value_counts().to_dict()\n",
    "value_counts_dict2_post = df_posts[\"ethical issue label post 2\"].value_counts().to_dict()\n",
    "\n",
    "d1 = value_counts_dict1_post\n",
    "d2 = value_counts_dict2_post\n",
    "\n",
    "merged_dict = Counter(d1) + Counter(d2)\n",
    "\n",
    "label_dict_post = dict(sorted(merged_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print(label_dict_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_dict1 = df[\"ethical issue label comment 1\"].value_counts().to_dict()\n",
    "value_counts_dict2 = df[\"ethical issue label comment 2\"].value_counts().to_dict()\n",
    "\n",
    "d1 = value_counts_dict1\n",
    "d2 = value_counts_dict2\n",
    "\n",
    "merged_dict = Counter(d1) + Counter(d2)\n",
    "\n",
    "result_dict = dict(sorted(merged_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethical_label_df(data, ethical_issue):\n",
    "    \n",
    "    if data == \"comment\":\n",
    "        df_issue1 = df[df[\"ethical issue label comment 1\"] == ethical_issue]\n",
    "        df_issue2 = df[df[\"ethical issue label comment 2\"] == ethical_issue]\n",
    "        \n",
    "    if data == \"post_full\":\n",
    "        df_issue1 = df[df[\"ethical issue label post 1\"] == ethical_issue]\n",
    "        df_issue2 = df[df[\"ethical issue label post 2\"] == ethical_issue]    \n",
    "        \n",
    "    elif data == \"post\":\n",
    "        df_issue1 = df_posts[df_posts[\"ethical issue label post 1\"] == ethical_issue]\n",
    "        df_issue2 = df_posts[df_posts[\"ethical issue label post 2\"] == ethical_issue]\n",
    "    \n",
    "    concat_issue = pd.concat([df_issue1, df_issue2], ignore_index = True)\n",
    "    \n",
    "    return concat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethical_label_df(\"post\", \"9. whistleblower retaliation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retal_comment = ethical_label_df(\"comment\", \"9. whistleblower retaliation\")\n",
    "df_manip_comment = ethical_label_df(\"comment\",\"5. manipulation\")\n",
    "df_priv_comment = ethical_label_df(\"comment\",\"0. privacy\")\n",
    "df_disc_comment = ethical_label_df(\"comment\",\"3. discrimination\")\n",
    "df_safety_comment = ethical_label_df(\"comment\",\"7. safety\")\n",
    "df_contmod_comment = ethical_label_df(\"comment\",\"1. content moderation\")\n",
    "df_misinfo_comment = ethical_label_df(\"comment\",\"4. misinformation\")\n",
    "df_algbias_comment = ethical_label_df(\"comment\",\"8. algorithmic bias\")\n",
    "df_cybsec_comment = ethical_label_df(\"comment\",\"6. cybersecurity\")\n",
    "df_addict_comment = ethical_label_df(\"comment\",\"2. addiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78abed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_score_dict = {\"Retal. \" + \"(\" + str(len(df_retal_comment)) + \")\":df_retal_comment[\"Score\"].mean(),\n",
    "                    \"Manip. \" + \"(\" + str(len(df_manip_comment))+ \")\":df_manip_comment[\"Score\"].mean(), \n",
    "                    \"Privacy \" + \"(\" + str(len(df_priv_comment))+ \")\":df_priv_comment[\"Score\"].mean(), \n",
    "                    \"Discrim. \" + \"(\" + str(len(df_disc_comment))+ \")\": df_disc_comment[\"Score\"].mean(), \n",
    "                    \"Safety \" + \"(\" + str(len(df_safety_comment))+ \")\":df_safety_comment[\"Score\"].mean(),\n",
    "                   \"ContMod. \" + \"(\" + str(len(df_contmod_comment))+ \")\":df_contmod_comment[\"Score\"].mean(), \n",
    "                    \"Misinfo. \" + \"(\" + str(len(df_misinfo_comment))+ \")\":df_misinfo_comment[\"Score\"].mean(),\n",
    "                   \"AlgBias. \" + \"(\" + str(len(df_algbias_comment))+ \")\":df_algbias_comment[\"Score\"].mean(), \n",
    "                    \"CybSec. \" + \"(\" + str(len(df_cybsec_comment))+ \")\":df_cybsec_comment[\"Score\"].mean(),\n",
    "                   \"Addiction \" + \"(\" + str(len(df_addict_comment))+ \")\":df_addict_comment[\"Score\"].mean()}\n",
    "\n",
    "label_score_dict = dict(sorted(label_score_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "label_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retal_post = ethical_label_df(\"post\", \"9. whistleblower retaliation\")\n",
    "df_manip_post = ethical_label_df(\"post\", \"5. manipulation\")\n",
    "df_priv_post = ethical_label_df(\"post\", \"0. privacy\")\n",
    "df_disc_post = ethical_label_df(\"post\", \"3. discrimination\")\n",
    "df_safety_post = ethical_label_df(\"post\", \"7. safety\")\n",
    "df_contmod_post = ethical_label_df(\"post\", \"1. content moderation\")\n",
    "df_misinfo_post = ethical_label_df(\"post\", \"4. misinformation\")\n",
    "df_algbias_post = ethical_label_df(\"post\", \"8. algorithmic bias\")\n",
    "df_cybsec_post = ethical_label_df(\"post\", \"6. cybersecurity\")\n",
    "df_addict_post = ethical_label_df(\"post\", \"2. addiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_score_dict_post = {\"Retal. \" + \"(\" + str(len(df_retal_post)) + \")\":df_retal_post[\"Post_Score\"].mean(), \n",
    "                         \"Manip. \" + \"(\" + str(len(df_manip_post)) + \")\":df_manip_post[\"Post_Score\"].mean(), \n",
    "                         \"Privacy \" + \"(\" + str(len(df_priv_post)) + \")\":df_priv_post[\"Post_Score\"].mean(), \n",
    "                         \"Discrim. \" + \"(\" + str(len(df_disc_post)) + \")\": df_disc_post[\"Post_Score\"].mean(),\n",
    "                         \"Safety \" + \"(\" + str(len(df_safety_post)) + \")\":df_safety_post[\"Post_Score\"].mean(), \n",
    "                         \"ContMod. \" + \"(\" + str(len(df_contmod_post)) + \")\":df_contmod_post[\"Post_Score\"].mean(),\n",
    "                         \"Misinfo. \" + \"(\" + str(len(df_misinfo_post)) + \")\":df_misinfo_post[\"Post_Score\"].mean(), \n",
    "                         \"AlgBias. \" + \"(\" + str(len(df_algbias_post)) + \")\":df_algbias_post[\"Post_Score\"].mean(),\n",
    "                         \"CybSec. \" + \"(\" +  str(len(df_cybsec_post)) + \")\":df_cybsec_post[\"Post_Score\"].mean(), \n",
    "                         \"Addiction \" + \"(\" + str(len(df_addict_post)) + \")\":df_addict_post[\"Post_Score\"].mean()}\n",
    "\n",
    "label_score_dict_post = dict(sorted(label_score_dict_post.items(), key=lambda item: item[1], reverse=True))\n",
    "        \n",
    "label_score_dict_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_numcom_dict_post = {\"Retal. \" + \"\\n\" + \"(\" +  str(len(df_retal_post)) + \")\":df_retal_post[\"Num_Comments\"].mean(), \n",
    "                         \"Manip. \" + \"\\n\" + \"(\" +  str(len(df_manip_post)) + \")\":df_manip_post[\"Num_Comments\"].mean(), \n",
    "                         \"Privacy \" + \"\\n\" + \"(\" +  str(len(df_priv_post)) + \")\":df_priv_post[\"Num_Comments\"].mean(), \n",
    "                         \"Discrim. \" + \"\\n\" + \"(\" +  str(len(df_disc_post)) + \")\":df_disc_post[\"Num_Comments\"].mean(),\n",
    "                         \"Safety \" + \"\\n\" + \"(\" +  str(len(df_safety_post)) + \")\":df_safety_post[\"Num_Comments\"].mean(), \n",
    "                         \"ContMod. \" + \"\\n\" + \"(\" +  str(len(df_contmod_post)) + \")\":df_contmod_post[\"Num_Comments\"].mean(),\n",
    "                         \"Misinfo. \" + \"\\n\" + \"(\" +  str(len(df_misinfo_post)) + \")\":df_misinfo_post[\"Num_Comments\"].mean(), \n",
    "                         \"Alg.Bias \" + \"\\n\" + \"(\" +  str(len(df_algbias_post)) + \")\":df_algbias_post[\"Num_Comments\"].mean(),\n",
    "                         \"CybSec. \" + \"\\n\" + \"(\" +  str(len(df_cybsec_post)) + \")\":df_cybsec_post[\"Num_Comments\"].mean(), \n",
    "                         \"Addiction \" + \"\\n\" + \"(\" +  str(len(df_addict_post)) + \")\":df_addict_post[\"Num_Comments\"].mean()}\n",
    "\n",
    "label_numcom_dict_post = dict(sorted(label_numcom_dict_post.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "label_numcom_dict_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unrelated_comment(df):\n",
    "    df = df[df[\"type label comment\"] == \"2. unrelated to whistleblowing\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ethical issue label comment 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_privacy = ethical_label_df(\"post_full\", \"0. privacy\")\n",
    "df_unrelated_privacy = unrelated_comment(df_full_privacy)\n",
    "df_full_retal = ethical_label_df(\"post_full\", \"9. whistleblower retaliation\")\n",
    "df_unrelated_retal = unrelated_comment(df_full_retal)\n",
    "df_full_manipulation = ethical_label_df(\"post_full\", \"5. manipulation\")\n",
    "df_unrelated_manipulation = unrelated_comment(df_full_manipulation)\n",
    "df_full_safety = ethical_label_df(\"post_full\", \"7. safety\")\n",
    "df_unrelated_safety = df_unrelated_safety = unrelated_comment(df_full_safety)\n",
    "df_full_content = ethical_label_df(\"post_full\", \"1. content moderation\")\n",
    "df_unrelated_content = df_unrelated_content = unrelated_comment(df_full_content)\n",
    "df_full_discrim = ethical_label_df(\"post_full\", \"3. discrimination\")\n",
    "df_full_misinfo = ethical_label_df(\"post_full\", \"4. misinformation\")\n",
    "df_full_cybsec = ethical_label_df(\"post_full\", \"6. cybersecurity\")\n",
    "df_full_addiction = ethical_label_df(\"post_full\", \"2. addiction\")\n",
    "df_full_algbias =  ethical_label_df(\"post_full\", \"8. algorithmic bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_full_addiction[df_full_addiction[\"stance comment\"] == \"1. against whistleblowing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_stances(df, stance):\n",
    "    df = df[df[\"stance comment\"] == stance]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for\n",
    "df_full_retal_pos = comment_stances(df_full_retal, \"0. for whistleblowing\")\n",
    "df_full_privacy_pos = comment_stances(df_full_privacy, \"0. for whistleblowing\")\n",
    "df_full_manipulation_pos = comment_stances(df_full_manipulation, \"0. for whistleblowing\")\n",
    "df_full_safety_pos = comment_stances(df_full_safety, \"0. for whistleblowing\")\n",
    "df_full_content_pos = comment_stances(df_full_content, \"0. for whistleblowing\")\n",
    "df_full_discrim_pos = comment_stances(df_full_discrim, \"0. for whistleblowing\")\n",
    "df_full_misinfo_pos = comment_stances(df_full_misinfo, \"0. for whistleblowing\")\n",
    "df_full_cybsec_pos = comment_stances(df_full_cybsec, \"0. for whistleblowing\")\n",
    "df_full_addiction_pos = comment_stances(df_full_addiction, \"0. for whistleblowing\")\n",
    "df_full_algbias_pos = comment_stances(df_full_algbias, \"0. for whistleblowing\")\n",
    "\n",
    "#against\n",
    "df_full_retal_neg = comment_stances(df_full_retal, \"1. against whistleblowing\")\n",
    "df_full_privacy_neg = comment_stances(df_full_privacy, \"1. against whistleblowing\")\n",
    "df_full_manipulation_neg = comment_stances(df_full_manipulation, \"1. against whistleblowing\")\n",
    "df_full_safety_neg = comment_stances(df_full_safety, \"1. against whistleblowing\")\n",
    "df_full_content_neg = comment_stances(df_full_content, \"1. against whistleblowing\")\n",
    "df_full_discrim_neg = comment_stances(df_full_discrim, \"1. against whistleblowing\")\n",
    "df_full_misinfo_neg = comment_stances(df_full_misinfo, \"1. against whistleblowing\")\n",
    "df_full_cybsec_neg = comment_stances(df_full_cybsec, \"1. against whistleblowing\")\n",
    "df_full_addiction_neg = comment_stances(df_full_addiction, \"1. against whistleblowing\")\n",
    "df_full_algbias_neg = comment_stances(df_full_algbias, \"1. against whistleblowing\")\n",
    "\n",
    "#neutral\n",
    "df_full_retal_neutral = comment_stances(df_full_retal, \"2. neutral\")\n",
    "df_full_privacy_neutral = comment_stances(df_full_privacy, \"2. neutral\")\n",
    "df_full_manipulation_neutral = comment_stances(df_full_manipulation, \"2. neutral\")\n",
    "df_full_safety_neutral = comment_stances(df_full_safety, \"2. neutral\")\n",
    "df_full_content_neutral = comment_stances(df_full_content, \"2. neutral\")\n",
    "df_full_discrim_neutral = comment_stances(df_full_discrim, \"2. neutral\")\n",
    "df_full_misinfo_neutral = comment_stances(df_full_misinfo, \"2. neutral\")\n",
    "df_full_cybsec_neutral = comment_stances(df_full_cybsec, \"2. neutral\")\n",
    "df_full_addiction_neutral = comment_stances(df_full_addiction, \"2. neutral\")\n",
    "df_full_algbias_neutral = comment_stances(df_full_algbias, \"2. neutral\")\n",
    "\n",
    "#unrelated\n",
    "df_full_retal_unrelated = comment_stances(df_full_retal, \"3. unrelated to whistleblowing\")\n",
    "df_full_privacy_unrelated = comment_stances(df_full_privacy, \"3. unrelated to whistleblowing\")\n",
    "df_full_manipulation_unrelated = comment_stances(df_full_manipulation, \"3. unrelated to whistleblowing\")\n",
    "df_full_safety_unrelated = comment_stances(df_full_safety, \"3. unrelated to whistleblowing\")\n",
    "df_full_content_unrelated = comment_stances(df_full_content, \"3. unrelated to whistleblowing\")\n",
    "df_full_discrim_unrelated = comment_stances(df_full_discrim, \"3. unrelated to whistleblowing\")\n",
    "df_full_misinfo_unrelated = comment_stances(df_full_misinfo, \"3. unrelated to whistleblowing\")\n",
    "df_full_cybsec_unrelated = comment_stances(df_full_cybsec, \"3. unrelated to whistleblowing\")\n",
    "df_full_addiction_unrelated = comment_stances(df_full_addiction, \"3. unrelated to whistleblowing\")\n",
    "df_full_algbias_unrelated = comment_stances(df_full_algbias, \"3. unrelated to whistleblowing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dict = {\n",
    "    'Retal.': {'Neutral': len(df_full_retal_neutral), 'Against': len(df_full_retal_neg), 'For': len(df_full_retal_pos), 'Unrelated': len(df_full_retal_unrelated)},\n",
    "    'Privacy': {'Neutral': len(df_full_privacy_neutral), 'Against': len(df_full_privacy_neg), 'For': len(df_full_privacy_pos), 'Unrelated': len(df_full_privacy_unrelated)},\n",
    "    'Manip.': {'Neutral': len(df_full_manipulation_neutral), 'Against': len(df_full_manipulation_neg), 'For': len(df_full_manipulation_pos), 'Unrelated': len(df_full_manipulation_unrelated)},\n",
    "    'Safety': {'Neutral': len(df_full_safety_neutral), 'Against': len(df_full_safety_neg), 'For': len(df_full_safety_pos), 'Unrelated': len(df_full_safety_unrelated)},\n",
    "    'ContMod.': {'Neutral': len(df_full_content_neutral), 'Against': len(df_full_content_neg), 'For': len(df_full_content_pos), 'Unrelated': len(df_full_content_unrelated)},\n",
    "    'Discrim.': {'Neutral': len(df_full_discrim_neutral), 'Against': len(df_full_discrim_neg), 'For': len(df_full_discrim_pos), 'Unrelated': len(df_full_discrim_unrelated)},\n",
    "    'Misinfo.': {'Neutral': len(df_full_misinfo_neutral), 'Against': len(df_full_misinfo_neg), 'For': len(df_full_misinfo_pos), 'Unrelated': len(df_full_misinfo_unrelated)},\n",
    "    'CybSec': {'Neutral': len(df_full_cybsec_neutral), 'Against': len(df_full_cybsec_neg), 'For': len(df_full_cybsec_pos), 'Unrelated': len(df_full_cybsec_unrelated)},\n",
    "    'Addiction': {'Neutral': len(df_full_addiction_neutral), 'Against': len(df_full_addiction_neg), 'For': len(df_full_addiction_pos), 'Unrelated': len(df_full_addiction_unrelated)},\n",
    "    'AlgBias': {'Neutral': len(df_full_algbias_neutral), 'Against': len(df_full_algbias_neg), 'For': len(df_full_algbias_pos), 'Unrelated': len(df_full_algbias_unrelated)}\n",
    "}\n",
    "\n",
    "#from dict to dataframe\n",
    "df_chart = pd.DataFrame(data_dict).T\n",
    "\n",
    "#calculate total width\n",
    "df_chart['Total'] = df_chart.sum(axis=1)\n",
    "\n",
    "#sort the bars by total width\n",
    "df_chart_sorted = df_chart.sort_values(by='Total', ascending=True).drop(columns='Total')\n",
    "\n",
    "colors = {\n",
    "    'Neutral': '#a3c2e1',   #dark blue\n",
    "    'Against': '#80c4f4',   #light blue\n",
    "    'For': '#49b3fe',       #lighter blue\n",
    "    'Unrelated': '#025d9d'  #lightest blue\n",
    "}\n",
    "\n",
    "#horizontal bar plot\n",
    "ax = df_chart_sorted.plot(kind='barh', stacked=True, figsize=(15, 10), color=[colors['Neutral'], colors['Against'], colors['For'], colors['Unrelated']])\n",
    "\n",
    "#place text on the bars\n",
    "for i, (row_name, row) in enumerate(df_chart_sorted.iterrows()):\n",
    "    cumulative_sum = 0\n",
    "    for j, (category, value) in enumerate(row.items()):\n",
    "        cumulative_sum += value\n",
    "        if value > 5:  #display text only if the value is greater\n",
    "            text_color = 'black' if category in ['Neutral', 'Against'] else 'white'\n",
    "            ax.text(\n",
    "                cumulative_sum - value / 2,\n",
    "                i,\n",
    "                str(value),\n",
    "                va='center',\n",
    "                ha='center',\n",
    "                fontsize=20,\n",
    "                color=text_color\n",
    "            )\n",
    "\n",
    "plt.xlabel('Number of Comments', fontsize=20)\n",
    "plt.ylabel('Ethical Issues Posts', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(loc='lower right', fontsize=24)\n",
    "plt.title('Comment Stances per Ethical Issue Posts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW DO THE SAME FOR THE COMMENTS\n",
    "\n",
    "#for\n",
    "df_retal_pos = comment_stances(df_retal_comment, \"0. for whistleblowing\")\n",
    "df_privacy_pos = comment_stances(df_priv_comment, \"0. for whistleblowing\")\n",
    "df_manipulation_pos = comment_stances(df_manip_comment, \"0. for whistleblowing\")\n",
    "df_safety_pos = comment_stances(df_safety_comment, \"0. for whistleblowing\")\n",
    "df_content_pos = comment_stances(df_contmod_comment, \"0. for whistleblowing\")\n",
    "df_discrim_pos = comment_stances(df_disc_comment, \"0. for whistleblowing\")\n",
    "df_misinfo_pos = comment_stances(df_misinfo_comment, \"0. for whistleblowing\")\n",
    "df_cybsec_pos = comment_stances(df_cybsec_comment, \"0. for whistleblowing\")\n",
    "df_addiction_pos = comment_stances(df_addict_comment, \"0. for whistleblowing\")\n",
    "df_algbias_pos = comment_stances(df_algbias_comment, \"0. for whistleblowing\")\n",
    "\n",
    "#against\n",
    "df_retal_neg = comment_stances(df_retal_comment, \"1. against whistleblowing\")\n",
    "df_privacy_neg = comment_stances(df_priv_comment, \"1. against whistleblowing\")\n",
    "df_manipulation_neg = comment_stances(df_manip_comment, \"1. against whistleblowing\")\n",
    "df_safety_neg = comment_stances(df_safety_comment, \"1. against whistleblowing\")\n",
    "df_content_neg = comment_stances(df_contmod_comment, \"1. against whistleblowing\")\n",
    "df_discrim_neg = comment_stances(df_disc_comment, \"1. against whistleblowing\")\n",
    "df_misinfo_neg = comment_stances(df_misinfo_comment, \"1. against whistleblowing\")\n",
    "df_cybsec_neg = comment_stances(df_cybsec_comment, \"1. against whistleblowing\")\n",
    "df_addiction_neg = comment_stances(df_addict_comment, \"1. against whistleblowing\")\n",
    "df_algbias_neg = comment_stances(df_algbias_comment, \"1. against whistleblowing\")\n",
    "\n",
    "#neutral\n",
    "df_retal_neutral = comment_stances(df_retal_comment, \"2. neutral\")\n",
    "df_privacy_neutral = comment_stances(df_priv_comment, \"2. neutral\")\n",
    "df_manipulation_neutral = comment_stances(df_manip_comment, \"2. neutral\")\n",
    "df_safety_neutral = comment_stances(df_safety_comment, \"2. neutral\")\n",
    "df_content_neutral = comment_stances(df_contmod_comment, \"2. neutral\")\n",
    "df_discrim_neutral = comment_stances(df_disc_comment, \"2. neutral\")\n",
    "df_misinfo_neutral = comment_stances(df_misinfo_comment, \"2. neutral\")\n",
    "df_cybsec_neutral = comment_stances(df_cybsec_comment, \"2. neutral\")\n",
    "df_addiction_neutral = comment_stances(df_addict_comment, \"2. neutral\")\n",
    "df_algbias_neutral = comment_stances(df_algbias_comment, \"2. neutral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contmod_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retal_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_priv_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manip_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_safety_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disc_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_misinfo_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cybsec_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addict_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_algbias_comment[\"stance comment\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dict = {\n",
    "    'Retal.': {'Neutral': len(df_retal_neutral), 'Against': len(df_retal_neg), 'For': len(df_retal_pos)},\n",
    "    'Privacy': {'Neutral': len(df_privacy_neutral), 'Against': len(df_privacy_neg), 'For': len(df_privacy_pos)},\n",
    "    'Manip.': {'Neutral': len(df_manipulation_neutral), 'Against': len(df_manipulation_neg), 'For': len(df_manipulation_pos)},\n",
    "    'Safety': {'Neutral': len(df_safety_neutral), 'Against': len(df_safety_neg), 'For': len(df_safety_pos)},\n",
    "    'ContMod.': {'Neutral': len(df_content_neutral), 'Against': len(df_content_neg), 'For': len(df_content_pos)},\n",
    "    'Discrim.': {'Neutral': len(df_discrim_neutral), 'Against': len(df_discrim_neg), 'For': len(df_discrim_pos)},\n",
    "    'Misinfo.': {'Neutral': len(df_misinfo_neutral), 'Against': len(df_misinfo_neg), 'For': len(df_misinfo_pos)},\n",
    "    'CybSec': {'Neutral': len(df_cybsec_neutral), 'Against': len(df_cybsec_neg), 'For': len(df_cybsec_pos)},\n",
    "    'Addiction': {'Neutral': len(df_addiction_neutral), 'Against': len(df_addiction_neg), 'For': len(df_addiction_pos)},\n",
    "    'AlgBias': {'Neutral': len(df_algbias_neutral), 'Against': len(df_algbias_neg), 'For': len(df_algbias_pos)}\n",
    "}\n",
    "\n",
    "#dict to df\n",
    "df_chart = pd.DataFrame(data_dict).T\n",
    "\n",
    "#total width\n",
    "df_chart['Total'] = df_chart[['Neutral', 'Against', 'For']].sum(axis=1)\n",
    "\n",
    "#sort total width in descending order\n",
    "df_chart_sorted = df_chart.sort_values(by='Total', ascending=True).drop(columns='Total')\n",
    "\n",
    "#sort data by category\n",
    "df_chart_sorted_within = df_chart_sorted[['Neutral', 'Against', 'For']]\n",
    "\n",
    "\n",
    "colors = {\n",
    "    'Neutral': '#80c4f4',   #light blue\n",
    "    'Against': '#49b3fe',   #blue\n",
    "    'For': '#025d9d'        #dark blue\n",
    "}\n",
    "\n",
    "#stacked horizontal bar plot\n",
    "ax = df_chart_sorted_within.plot(kind='barh', stacked=True, figsize=(15, 10), color=[colors['Neutral'], colors['Against'], colors['For']])\n",
    "\n",
    "\n",
    "for i, (row_name, row) in enumerate(df_chart_sorted_within.iterrows()):\n",
    "    cumulative_sum = 0\n",
    "    for category in ['Neutral', 'Against', 'For']:\n",
    "        value = row[category]\n",
    "        cumulative_sum += value\n",
    "        if value > 2:\n",
    "            text_color = 'black' if category in ['Neutral', 'Against'] else 'white'\n",
    "            ax.text(\n",
    "                cumulative_sum - value / 2,\n",
    "                i,\n",
    "                str(value),\n",
    "                va='center',\n",
    "                ha='center',\n",
    "                fontsize=20,\n",
    "                color=text_color\n",
    "            )\n",
    "\n",
    "plt.xlabel('Number of Comments', fontsize=18)\n",
    "plt.ylabel('Ethical Issues Comments', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(loc='lower right', fontsize=24)\n",
    "plt.title('Stance comment per ethical issue comment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_labels = []\n",
    "comment_label_scores = []\n",
    "\n",
    "label_score_dict.update({\"Mean Score\":df[\"Score\"].mean()})\n",
    "\n",
    "label_score_dict = sorted(label_score_dict.items(), key=lambda x:x[1])\n",
    "\n",
    "label_score_dict = dict(label_score_dict)\n",
    "\n",
    "for k, v in label_score_dict.items():\n",
    "    comment_labels.append(k)\n",
    "    comment_label_scores.append(v)\n",
    "\n",
    "x = comment_label_scores\n",
    "labels = comment_labels\n",
    "\n",
    "#bar plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "highlight_index = 3 #highlight color\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "colors[highlight_index] = '#025d9d'\n",
    "\n",
    "\n",
    "bars = plt.bar(labels, x, color=colors)\n",
    "\n",
    "plt.title(\"Ethical Labels Score Means (Comments)\", fontsize = 20)\n",
    "plt.xlabel('Ethical Labels', fontsize = 22)\n",
    "plt.ylabel('Score', fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks(rotation=25, fontsize = 20)\n",
    "\n",
    "#value on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize = 20\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_labels = []\n",
    "post_label_scores = []\n",
    "\n",
    "label_score_dict_post.update({\"Mean Score\":df_posts[\"Post_Score\"].mean()})\n",
    "\n",
    "label_score_dict_post = sorted(label_score_dict_post.items(), key=lambda x:x[1])\n",
    "\n",
    "label_score_dict_post = dict(label_score_dict_post)\n",
    "\n",
    "for k, v in label_score_dict_post.items():\n",
    "    post_labels.append(k)\n",
    "    post_label_scores.append(v)\n",
    "\n",
    "x = post_label_scores\n",
    "labels = post_labels\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "highlight_index = 4 #highlight color index change if needed\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "colors[highlight_index] = '#025d9d'\n",
    "\n",
    "\n",
    "bars = plt.bar(labels, x, color=colors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Ethical Labels Score Means (Posts)\",fontsize =  20)\n",
    "plt.xlabel('Ethical Labels',fontsize =  22)\n",
    "plt.ylabel('Score',fontsize =  22)\n",
    "plt.xticks(rotation=25, fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize = 20\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_numcom_dict_post.update({\"Mean Num Comments\":df_posts[\"Num_Comments\"].mean()})\n",
    "\n",
    "label_numcom_dict_post = sorted(label_numcom_dict_post.items(), key=lambda x:x[1])\n",
    "\n",
    "label_numcom_dict_post = dict(label_numcom_dict_post)\n",
    "\n",
    "label_numcom_dict_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_labels = []\n",
    "post_label_numcoms = []\n",
    "\n",
    "label_numcom_dict_post.update({\"Mean\" + \"\\n\" \"Num.\" + \"\\n\" + \"Comments\":df_posts[\"Num_Comments\"].mean()})\n",
    "\n",
    "label_numcom_dict_post = sorted(label_numcom_dict_post.items(), key=lambda x:x[1])\n",
    "\n",
    "label_numcom_dict_post = dict(label_numcom_dict_post)\n",
    "\n",
    "for k, v in label_numcom_dict_post.items():\n",
    "    post_labels.append(k)\n",
    "    post_label_numcoms.append(v)\n",
    "\n",
    "x = post_label_numcoms\n",
    "labels = post_labels\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "highlight_index = 6\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "colors[highlight_index] = '#025d9d'\n",
    "\n",
    "\n",
    "bars = plt.bar(labels, x, color=colors)\n",
    "\n",
    "\n",
    "plt.title(\"Ethical Labels Num Comments Means (Posts)\", fontsize = 20)\n",
    "plt.xlabel('Ethical Labels', fontsize = 22)\n",
    "plt.ylabel('Num Comments', fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "plt.xticks(rotation=18, fontsize = 18)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize = 20\n",
    "    )\n",
    "\n",
    "#plt.savefig(\"results/EthicalLabelsNumComMeansPosts.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [1, 1, 3, 3, 6, 7, 14, 18, 30, 43, 50]\n",
    "x_labels = [\"AlgBias.\", \"Addiction\", \"CybSec.\", \"ContMod.\", \"Misinfo.\", \"Safety\", \"Unrelated\", \"Discrim.\", \n",
    "            \"Retal.\", \"Privacy\", \"Manip.\"]\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "\n",
    "bars = plt.bar(x_labels, x_values, color=colors)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize = 20\n",
    "    )\n",
    "\n",
    "plt.title(\"Ethical Issue post by Absolute Frequency\", fontsize = 20)\n",
    "plt.xlabel('Ethical Labels', fontsize = 22)\n",
    "plt.ylabel('Absolute Frequency', fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks(rotation=18, fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [2, 2, 9, 46, 58, 61, 176, 215, 289, 408, 736]\n",
    "x_labels = [\"AlgBias.\", \"Addiction\", \"CybSec.\", \"Safety\", \"Misinfo.\", \"ContMod.\", \"Discrim.\", \n",
    "            \"Privacy\", \"Retal.\",  \"Manip.\", \"Unrelated\"]\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "\n",
    "bars = plt.bar(x_labels, x_values, color=colors)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize = 20\n",
    "    )\n",
    "\n",
    "plt.title(\"Ethical Issue Post-Comment by Absolute Frequency\", fontsize = 20)\n",
    "plt.xlabel('Ethical Labels', fontsize = 22)\n",
    "plt.ylabel('Absolute Frequency', fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks(rotation=18, fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [1, 3, 16, 19, 26, 50, 84, 100, 121, 1078]\n",
    "x_labels = [\"Addiction\", \"CybSec.\", \"Misinfo.\", \"ContMod.\", \"Safety\", \"Discrim.\", \n",
    "            \"Privacy\", \"Retal.\", \"Manip.\", \"Unrelated\"]\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "\n",
    "bars = plt.bar(x_labels, x_values, color=colors)\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%d' % int(height),\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize = 20\n",
    "    )\n",
    "    \n",
    "plt.title(\"Ethical Issue Comments by Absolute Frequency\", fontsize = 20)\n",
    "plt.xlabel('Ethical Labels', fontsize = 22)\n",
    "plt.ylabel('Absolute Frequency', fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.xticks(rotation=18, fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-taxation",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Research question 2 stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.read_excel(\"data/finalannotation+poststats+date.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"Comment_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats[[\"Post_ID\", \"Post_Score\", \"ethical issue label post 1\", \"ethical issue label post 2\", \n",
    "                     \"Comment_ID\", \"Score\", \"ethical issue label comment 1\", \"ethical issue label comment 2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine ethical issues to issue pair post, tuple\n",
    "df_stats[\"Issue Pair Post\"] = df_stats.apply(lambda row: (row[\"ethical issue label post 1\"], \n",
    "                                                          row[\"ethical issue label post 2\"]), axis=1)\n",
    "\n",
    "#create group ids within similar post ids to see unique issue pairs\n",
    "df_stats[\"Group_ID\"] = df_stats.groupby([\"Post_ID\", \"Issue Pair Post\"]).ngroup()\n",
    "\n",
    "def count_unrelated(series):\n",
    "    return (series == \"11. unrelated\").sum()\n",
    "\n",
    "#count the amount of unrelated comment per specific issue pair post\n",
    "df_stats[\"Unrelated Count\"] = df_stats.groupby(\"Group_ID\")[\"ethical issue label comment 1\"].transform(count_unrelated)\n",
    "\n",
    "#create issue pair for the comments\n",
    "df_stats[\"Issue Pair Comment\"] = df_stats.apply(lambda row: (row[\"ethical issue label comment 1\"], row[\"ethical issue label comment 2\"]), axis=1)\n",
    "\n",
    "old_len_unrelated = len(df_stats)\n",
    "old_len_related = len(df_stats[df_stats[\"ethical issue label comment 1\"] != \"11. unrelated\"])\n",
    "\n",
    "#extract numeric part from string and convert it to integer so we can sort the strings by their number\n",
    "def extract_number(s):\n",
    "    match = re.match(r\"(\\d+)\\.\", s)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "#sort tuples based on the numeric part\n",
    "def sort_tuple(t):\n",
    "    #extract numbers and sort tuples\n",
    "    sorted_tuple = sorted(t, key=lambda x: extract_number(x))\n",
    "    return tuple(sorted_tuple)\n",
    "\n",
    "#sort the issue pair tuples\n",
    "df_stats[\"Issue Pair Post\"] = df_stats[\"Issue Pair Post\"].apply(sort_tuple)\n",
    "df_stats[\"Issue Pair Comment\"] = df_stats[\"Issue Pair Comment\"].apply(sort_tuple)\n",
    "\n",
    "\n",
    "#new column to check matches between issue pairs post and comments\n",
    "df_stats[\"Match\"] = df_stats.apply(lambda row: list(row[\"Issue Pair Post\"]) == list(row[\"Issue Pair Comment\"]), axis=1)\n",
    "df_stats[\"Non_Match\"] = df_stats.apply(lambda row: list(row[\"Issue Pair Post\"]) != list(row[\"Issue Pair Comment\"]), axis=1)\n",
    "\n",
    "#adding a suffix to the post id when posts with the same id are different\n",
    "def add_suffix(group):\n",
    "    unique_pairs = group[\"Issue Pair Post\"].unique()\n",
    "    pair_to_suffix = {pair: f\"_{i}\" if i > 0 else \"\" for i, pair in enumerate(unique_pairs)}\n",
    "    group[\"Post_ID_Modified\"] = group[\"Post_ID\"] + group[\"Issue Pair Post\"].map(pair_to_suffix)\n",
    "    return group\n",
    "\n",
    "df_stats = df_stats.groupby(\"Post_ID\").apply(add_suffix)\n",
    "\n",
    "#group by modified post id and count the matches within each group\n",
    "match_counts = df_stats.groupby(\"Post_ID_Modified\")[\"Match\"].sum().reset_index()\n",
    "match_counts.rename(columns={\"Match\": \"Match Count\"}, inplace=True)\n",
    "\n",
    "non_match_counts = df_stats.groupby(\"Post_ID_Modified\")[\"Non_Match\"].sum().reset_index()\n",
    "non_match_counts.rename(columns={\"Non_Match\": \"Non_Match Count\"}, inplace=True)\n",
    "\n",
    "#merge the match counts back into the original dataframe\n",
    "df_stats = df_stats.merge(match_counts, on=\"Post_ID_Modified\")\n",
    "df_stats = df_stats.merge(non_match_counts, on=\"Post_ID_Modified\")\n",
    "\n",
    "#df_stats = df_stats.drop(columns = \"Group_ID\")\n",
    "\n",
    "df_stats[\"Post_ID\"] = df_stats[\"Post_ID_Modified\"]\n",
    "df_stats[\"Comment_Score_Mean\"] = df_stats.groupby(\"Post_ID\")[\"Score\"].transform(\"mean\")\n",
    "df_stats[\"Comment_Score_Mean\"] = df_stats[\"Comment_Score_Mean\"].round(2)\n",
    "df_stats.drop(columns=[\"Group_ID\", \"Post_ID_Modified\"], inplace=True)\n",
    "df_stats[\"Num Comments\"] = df_stats.groupby(\"Post_ID\")[\"Comment_ID\"].transform(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_post = df_stats.drop_duplicates(\"Post_ID\")\n",
    "df_stats_post[\"Unrelated Count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_post[\"Match Count\"].sum() + df_stats_post[\"Non_Match Count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_stats[df_stats[\"Issue Pair Post\"].apply(lambda x: \"0. privacy\" in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_related = df_stats[df_stats[\"Issue Pair Comment\"].apply(lambda x: \"11. unrelated\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_related = df_stats_related.loc[df_stats_related.groupby(\"Post_ID\")[\"Score\"].idxmax()]\n",
    "df_stats_unrelated = df_stats.loc[df_stats.groupby(\"Post_ID\")[\"Score\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_related[\"Issue Pair Comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_post_ids = df_stats_related[\"Post_ID\"]\n",
    "\n",
    "df_stats_unrelated = df_stats_unrelated[~df_stats_unrelated[\"Post_ID\"].isin(overlapping_post_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"Total Percentage of Match Unrelated\"] = round(df_stats_post[\"Match Count\"].sum() / old_len_unrelated, 2)\n",
    "df_stats[\"Total Percentage of Match Related\"] = round(df_stats_post[\"Match Count\"].sum() / old_len_related, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats.drop(columns = [\"ethical issue label post 1\", \"ethical issue label post 2\",\n",
    "                                    \"ethical issue label comment 1\", \"ethical issue label comment 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats.rename(columns={\"Score\": \"Comment_Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_excel(\"data/dataRQ2full.xlsx\")\n",
    "df_stats_related.to_excel(\"data/dataRQ2relatedscore.xlsx\")\n",
    "df_stats_unrelated.to_excel(\"data/dataRQ2unrelatedscore.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ethical issue label post 2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rq2full = pd.read_excel(\"data/dataRQ2full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rq2full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rq2full = df_rq2full.drop_duplicates(\"Post_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rq2full[\"Unrelated Count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rq2_issues(frame, issue):\n",
    "    frame = frame[frame[\"Issue Pair Post\"].apply(lambda x: issue in x)]\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_privstats = rq2_issues(df_rq2full, \"0. privacy\")\n",
    "df_contentstats = rq2_issues(df_rq2full, \"1. content moderation\")\n",
    "df_addictstats = rq2_issues(df_rq2full, \"2. addiction\")\n",
    "df_discstats = rq2_issues(df_rq2full, \"3. discrimination\")\n",
    "df_misinfstats = rq2_issues(df_rq2full, \"4. misinformation\")\n",
    "df_manipstats = rq2_issues(df_rq2full, \"5. manipulation\")\n",
    "df_cybsecstats = rq2_issues(df_rq2full, \"6. cybersecurity\")\n",
    "df_safetystats = rq2_issues(df_rq2full, \"7. safety\")\n",
    "df_algbiasstats = rq2_issues(df_rq2full, \"8. algorithmic bias\")\n",
    "df_retalstats = rq2_issues(df_rq2full, \"9. whistleblower retaliation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [\n",
    "    df_privstats,\n",
    "    df_contentstats,\n",
    "    df_addictstats,\n",
    "    df_discstats,\n",
    "    df_misinfstats,\n",
    "    df_manipstats,\n",
    "    df_cybsecstats,\n",
    "    df_safetystats,\n",
    "    df_algbiasstats,\n",
    "    df_retalstats]\n",
    "\n",
    "stats_label = [\n",
    "    \"privacy\",\n",
    "    \"content moderation\",\n",
    "    \"addiction\",\n",
    "    \"discrimination\",\n",
    "    \"misinformation\",\n",
    "    \"manipulation\",\n",
    "    \"cybersecurity\",\n",
    "    \"safety\",\n",
    "    \"algorithmic bias\",\n",
    "    \"whistleblower retaliation\"\n",
    "]\n",
    "\n",
    "stats_list = []\n",
    "\n",
    "for i in df_list:\n",
    "    unrel_count = i[\"Unrelated Count\"].sum()\n",
    "    stats_list.append(unrel_count)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_match_check(df):\n",
    "\n",
    "    df = df.sort_values(by = \"Issue Pair Comment\")\n",
    "    df = df[[\"Issue Pair Post\", \"Issue Pair Comment\", \"Match\"]]\n",
    "    df = df[df[\"Issue Pair Comment\"] != \"('11. unrelated', '11. unrelated')\"]\n",
    "    df = df[df[\"Match\"] == False]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_privstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_manipstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_retalstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_discstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_safetystats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_contentstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_algbiasstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match_check(df_misinfstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unrel_dict = {\"Retal.\":df_retalstats[\"Unrelated Count\"].mean(), \n",
    "                         \"Manip.\":df_manipstats[\"Unrelated Count\"].mean(), \n",
    "                         \"Privacy\":df_privstats[\"Unrelated Count\"].mean(), \n",
    "                         \"Discrim.\":df_discstats[\"Unrelated Count\"].mean(),\n",
    "                         \"Safety\":df_safetystats[\"Unrelated Count\"].mean(), \n",
    "                         \"ContMod.\":df_contentstats[\"Unrelated Count\"].mean(),\n",
    "                         \"Misinfo.\":df_misinfstats[\"Unrelated Count\"].mean(), \n",
    "                         \"Alg.Bias\":df_algbiasstats[\"Unrelated Count\"].mean(),\n",
    "                         \"CybSec.\":df_cybsecstats[\"Unrelated Count\"].mean(), \n",
    "                         \"Addiction\":df_addictstats[\"Unrelated Count\"].mean(), \n",
    "                         \"Mean Num\":df_rq2full[\"Unrelated Count\"].mean()}\n",
    "\n",
    "df_unrel_dict = dict(sorted(df_unrel_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "df_unrel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_dict = {\"Retal.\":df_retalstats[\"Match Count\"].mean(), \n",
    "                         \"Manip.\":df_manipstats[\"Match Count\"].mean(), \n",
    "                         \"Privacy\":df_privstats[\"Match Count\"].mean(), \n",
    "                         \"Discrim.\":df_discstats[\"Match Count\"].mean(),\n",
    "                         \"Safety\":df_safetystats[\"Match Count\"].mean(), \n",
    "                         \"ContMod.\":df_contentstats[\"Match Count\"].mean(),\n",
    "                         \"Misinfo.\":df_misinfstats[\"Match Count\"].mean(), \n",
    "                         \"Alg.Bias\":df_algbiasstats[\"Match Count\"].mean(),\n",
    "                         \"CybSec.\":df_cybsecstats[\"Match Count\"].mean(), \n",
    "                         \"Addiction\":df_addictstats[\"Match Count\"].mean(),\n",
    "                         \"Mean Num\":df_rq2full[\"Match Count\"].mean()}\n",
    "\n",
    "df_match_dict = dict(sorted(df_match_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "df_match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonmatch_dict = {\"Retal.\":df_retalstats[\"Non_Match Count\"].mean(), \n",
    "                         \"Manip.\":df_manipstats[\"Non_Match Count\"].mean(), \n",
    "                         \"Privacy\":df_privstats[\"Non_Match Count\"].mean(), \n",
    "                         \"Discrim.\":df_discstats[\"Non_Match Count\"].mean(),\n",
    "                         \"Safety\":df_safetystats[\"Non_Match Count\"].mean(), \n",
    "                         \"ContMod.\":df_contentstats[\"Non_Match Count\"].mean(),\n",
    "                         \"Misinfo.\":df_misinfstats[\"Non_Match Count\"].mean(), \n",
    "                         \"Alg.Bias\":df_algbiasstats[\"Non_Match Count\"].mean(),\n",
    "                         \"CybSec.\":df_cybsecstats[\"Non_Match Count\"].mean(), \n",
    "                         \"Addiction\":df_addictstats[\"Non_Match Count\"].mean(),\n",
    "                         \"Mean Num\":df_rq2full[\"Non_Match Count\"].mean()}\n",
    "\n",
    "df_nonmatch_dict = dict(sorted(df_nonmatch_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "df_nonmatch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_labels = []\n",
    "stats_scores = []\n",
    "\n",
    "df_unrel_dict = sorted(df_unrel_dict.items(), key=lambda x:x[1])\n",
    "\n",
    "df_unrel_dict = dict(df_unrel_dict)\n",
    "\n",
    "for k, v in df_unrel_dict.items():\n",
    "    stats_labels.append(k)\n",
    "    stats_scores.append(v)\n",
    "\n",
    "x = stats_scores\n",
    "labels = stats_labels\n",
    "#bar plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "highlight_index = 7 \n",
    "\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe'\n",
    "         , '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "colors[highlight_index] = '#025d9d'\n",
    "\n",
    "\n",
    "bars = plt.bar(labels, x, color=colors)\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        \"%.2f\" % height, \n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=20\n",
    "    )\n",
    "\n",
    "plt.title(\"Mean Number of Unrelated Comments per Ethical Issue\", fontsize = 20)\n",
    "plt.xlabel(\"Ethical Labels\", fontsize = 22)\n",
    "plt.ylabel(\"Unrelated Comments mean\", fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "plt.xticks(rotation=18, fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_labels = []\n",
    "stats_scores = []\n",
    "\n",
    "df_match_dict.update({\"Mean Num\":df_rq2full[\"Match Count\"].mean()})\n",
    "\n",
    "df_match_dict = sorted(df_match_dict.items(), key=lambda x:x[1])\n",
    "\n",
    "df_match_dict = dict(df_match_dict)\n",
    "\n",
    "for k, v in df_match_dict.items():\n",
    "    stats_labels.append(k)\n",
    "    stats_scores.append(v)\n",
    "\n",
    "x = stats_scores\n",
    "labels = stats_labels\n",
    "#bar plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "highlight_index = 6 \n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe'\n",
    "         , '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "colors[highlight_index] = '#025d9d'\n",
    "\n",
    "\n",
    "bars = plt.bar(labels, x, color=colors)\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        '%.2f' % height,  # Format the height with 2 decimal places\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=20\n",
    "    )\n",
    "\n",
    "plt.title(\"Mean Number of Matching Comments per Ethical Issue\", fontsize = 20)\n",
    "plt.xlabel(\"Ethical Labels\", fontsize = 22)\n",
    "plt.ylabel(\"Matching Comments mean\", fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "plt.xticks(rotation=22, fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_labels = []\n",
    "stats_scores = []\n",
    "\n",
    "df_nonmatch_dict.update({\"Mean Num\":df_rq2full[\"Non_Match Count\"].mean()})\n",
    "\n",
    "df_nonmatch_dict = sorted(df_nonmatch_dict.items(), key=lambda x:x[1])\n",
    "\n",
    "df_nonmatch_dict = dict(df_nonmatch_dict)\n",
    "\n",
    "for k, v in df_nonmatch_dict.items():\n",
    "    stats_labels.append(k)\n",
    "    stats_scores.append(v)\n",
    "\n",
    "x = stats_scores\n",
    "labels = stats_labels\n",
    "#bar plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "highlight_index = 4\n",
    "\n",
    "colors = ['#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe','#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe', '#49b3fe'\n",
    "         , '#49b3fe', '#49b3fe', '#49b3fe']\n",
    "colors[highlight_index] = '#025d9d'\n",
    "\n",
    "\n",
    "bars = plt.barh(labels, x, color=colors)\n",
    "\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(\n",
    "        width- 0.1,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        '{:.2f}'.format(width),\n",
    "        ha='right',  \n",
    "        va='center',  \n",
    "        fontsize=14,\n",
    "        color='white'\n",
    "    )\n",
    "    \n",
    "    \n",
    "plt.title(\"Mean Number of Non-Matching Comments per Ethical Issue\", fontsize = 20)\n",
    "plt.xlabel(\"Non-Matching comments mean\", fontsize = 22)\n",
    "plt.ylabel(\"Ethical Labels\", fontsize = 22)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "plt.xticks(fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted(set(df_match_dict.keys()).union(df_unrel_dict.keys()).union(df_nonmatch_dict.keys()))\n",
    "\n",
    "#start data lists with zeros\n",
    "data1 = [df_match_dict.get(cat, 0) for cat in categories]\n",
    "data2 = [df_unrel_dict.get(cat, 0) for cat in categories]\n",
    "data3 = [df_nonmatch_dict.get(cat, 0) for cat in categories]\n",
    "\n",
    "#calculate total values for sorting\n",
    "total_values = [data1[i] + data2[i] + data3[i] for i in range(len(categories))]\n",
    "\n",
    "#combine categories and total values\n",
    "categories_with_totals = list(zip(categories, total_values))\n",
    "\n",
    "#sort based on total values\n",
    "sorted_categories_with_totals = sorted(categories_with_totals, key=lambda x: x[1])\n",
    "\n",
    "#unzip sorted categories and values\n",
    "sorted_categories, sorted_totals = zip(*sorted_categories_with_totals)\n",
    "\n",
    "#recalculate sorted data lists\n",
    "sorted_data1 = [df_match_dict.get(cat, 0) for cat in sorted_categories]\n",
    "sorted_data2 = [df_unrel_dict.get(cat, 0) for cat in sorted_categories]\n",
    "sorted_data3 = [df_nonmatch_dict.get(cat, 0) for cat in sorted_categories]\n",
    "\n",
    "#horizontal stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "#define the bars\n",
    "bars1 = ax.barh(sorted_categories, sorted_data1, label='Mean Match Comments', color='#80c4f4')\n",
    "bars2 = ax.barh(sorted_categories, sorted_data2, left=sorted_data1, label='Mean Unrelated Comments', color='#49b3fe')\n",
    "bars3 = ax.barh(sorted_categories, sorted_data3, left=[i + j for i, j in zip(sorted_data1, sorted_data2)], \n",
    "                label='Mean Non-Match Comments', color='#025d9d')\n",
    "\n",
    "#text labels on the bars\n",
    "for i, (bar1, bar2, bar3) in enumerate(zip(bars1, bars2, bars3)):\n",
    "    width1 = bar1.get_width()\n",
    "    width2 = bar2.get_width()\n",
    "    width3 = bar3.get_width()\n",
    "    \n",
    "    #add text if the width is above the threshold\n",
    "    if width1 > 0.5:\n",
    "        ax.text(\n",
    "            width1 / 2,  #middle of the first segment\n",
    "            bar1.get_y() + bar1.get_height() / 2,\n",
    "            '{:.1f}'.format(width1),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            fontsize=20,\n",
    "            color='black'\n",
    "        )\n",
    "    \n",
    "    if width2 > 0.5:\n",
    "        ax.text(\n",
    "            width1 + width2 / 2,  #middle of the second segment\n",
    "            bar2.get_y() + bar2.get_height() / 2,\n",
    "            '{:.1f}'.format(width2),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            fontsize=20,\n",
    "            color='white'\n",
    "        )\n",
    "    \n",
    "    if width3 > 0.5:\n",
    "        ax.text(\n",
    "            width1 + width2 + width3 / 2,  #middle of the third segment\n",
    "            bar3.get_y() + bar3.get_height() / 2,\n",
    "            '{:.1f}'.format(width3),\n",
    "            ha='center',\n",
    "            va='center',\n",
    "            fontsize=20,\n",
    "            color='white'\n",
    "        )\n",
    "\n",
    "\n",
    "ax.set_xlabel('Mean Values', fontsize=24)\n",
    "ax.set_ylabel('Ethical Issues', fontsize=24)\n",
    "ax.set_title('Horizontal Stacked Bar Chart', fontsize=24)\n",
    "ax.set_xticks([])\n",
    "plt.yticks(fontsize=24)\n",
    "ax.legend(fontsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted(set(df_match_dict.keys()).union(df_unrel_dict.keys()).union(df_nonmatch_dict.keys()))\n",
    "\n",
    "#start data lists with zeros\n",
    "data1 = [df_match_dict.get(cat, 0) for cat in categories]\n",
    "data2 = [df_unrel_dict.get(cat, 0) for cat in categories]\n",
    "data3 = [df_nonmatch_dict.get(cat, 0) for cat in categories]\n",
    "\n",
    "#calculate total values for sorting\n",
    "total_values = [data1[i] + data2[i] + data3[i] for i in range(len(categories))]\n",
    "\n",
    "#combine categories and total values\n",
    "categories_with_totals = list(zip(categories, total_values))\n",
    "\n",
    "#sort based on total values\n",
    "sorted_categories_with_totals = sorted(categories_with_totals, key=lambda x: x[1])\n",
    "\n",
    "#unzip sorted categories and values\n",
    "sorted_categories, sorted_totals = zip(*sorted_categories_with_totals)\n",
    "\n",
    "#recalculate sorted data lists\n",
    "sorted_data1 = [df_match_dict.get(cat, 0) for cat in sorted_categories]\n",
    "sorted_data2 = [df_unrel_dict.get(cat, 0) for cat in sorted_categories]\n",
    "sorted_data3 = [df_nonmatch_dict.get(cat, 0) for cat in sorted_categories]\n",
    "\n",
    "#vertical bar chart\n",
    "fig, ax = plt.subplots(figsize=(25, 18))\n",
    "\n",
    "bar_width = 0.25\n",
    "\n",
    "#positions for the bars\n",
    "r1 = np.arange(len(sorted_categories))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "\n",
    "#define the bars\n",
    "bars1 = ax.bar(r1, sorted_data1, color='#80c4f4', width=bar_width, label='Mean Match Count')\n",
    "bars2 = ax.bar(r2, sorted_data2, color='#49b3fe', width=bar_width, label='Mean Unrelated Count')\n",
    "bars3 = ax.bar(r3, sorted_data3, color='#025d9d', width=bar_width, label='Mean Non-Match Count')\n",
    "\n",
    "#labels on the bars\n",
    "for i, (bar1, bar2, bar3) in enumerate(zip(bars1, bars2, bars3)):\n",
    "    height1 = bar1.get_height()\n",
    "    height2 = bar2.get_height()\n",
    "    height3 = bar3.get_height()\n",
    "\n",
    "    #add text if the height is above the threshold\n",
    "    if height1 > 0.25:\n",
    "        ax.text(\n",
    "            bar1.get_x() + bar1.get_width() / 2,  # Center of the bar\n",
    "            height1 - 0.4,  # Just above the top of the bar\n",
    "            '{:.1f}'.format(height1),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=24,\n",
    "            color='black'\n",
    "        )\n",
    "    \n",
    "    if height2 > 0.25:\n",
    "        ax.text(\n",
    "            bar2.get_x() + bar2.get_width() / 2, \n",
    "            height2 - 0.3, \n",
    "            '{:.1f}'.format(height2),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=24,\n",
    "            color='black'\n",
    "        )\n",
    "    \n",
    "    if height3 > 0.25:\n",
    "        ax.text(\n",
    "            bar3.get_x() + bar3.get_width() / 2,  \n",
    "            height3,\n",
    "            '{:.1f}'.format(height3),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=24,\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "\n",
    "ax.set_xlabel('Categories', fontsize=30)\n",
    "ax.set_ylabel('Values', fontsize=30)\n",
    "ax.set_title('Vertical Bar Chart', fontsize=30)\n",
    "ax.set_xticks([r + bar_width for r in range(len(sorted_categories))])\n",
    "ax.set_xticklabels(sorted_categories, ha='right', fontsize=22)\n",
    "ax.legend(fontsize=18)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
