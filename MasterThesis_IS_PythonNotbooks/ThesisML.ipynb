{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "#machine learning imports\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "#neural network imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "#nltk stuff, uncomment if needed\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/finalannotation.xlsx\")\n",
    "df_wbs = pd.read_excel(\"data/finalannotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"new class type\", \"new ethical issues\", \"Unnamed: 17\"])\n",
    "df_wbs = df_wbs.drop(columns = [\"new class type\", \"new ethical issues\", \"Unnamed: 17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "wblist = [\"0. for whistleblowing\", \"1. against whistleblowing\", \"2. neutral\"]\n",
    "\n",
    "df_wbs[\"stance comment\"] = df_wbs[\"stance comment\"].str.replace(\"0. for whistleblowing\", \"related to whistleblowing\")\n",
    "df_wbs[\"stance comment\"] = df_wbs[\"stance comment\"].str.replace(\"1. against whistleblowing\", \"related to whistleblowing\")\n",
    "df_wbs[\"stance comment\"] = df_wbs[\"stance comment\"].str.replace(\"2. neutral\", \"related to whistleblowing\")\n",
    "df_wbs[\"stance comment\"] = df_wbs[\"stance comment\"].str.replace(\"3. unrelated to whistleblowing\", \"unrelated to whistleblowing\")\n",
    "\n",
    "\n",
    "df_wbs[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    '''This function preprocesses the text to prepare it for text mining tasks.\n",
    "    The text is first lowercased and tokenized, then stopwords are removed, and the text is lemmatized.\n",
    "    '''\n",
    "    #tokenize and lowercase the text + define the stopwords and instantiate lemmatizer\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "   \n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    #create a single string from the tokens\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_body\"] = df[\"Body\"].apply(preprocess_text)\n",
    "df_wbs[\"cleaned_body\"] = df_wbs[\"Body\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related = df[df[\"stance comment\"] != \"3. unrelated to whistleblowing\"]\n",
    "df_related_binary = df_related[df_related[\"stance comment\"] != \"2. neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#had some issues with extracting data from dataframe so turned it to a list and also double checked with some prints\n",
    "text_data = df_related['cleaned_body'].tolist()\n",
    "print(f'Number of documents: {len(text_data)}')\n",
    "print(f'Sample documents: {text_data[:5]}')\n",
    "print(\"\\n\")\n",
    "\n",
    "#setting up vectorizer with parameter tuning\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95,  #setting max document frequency\n",
    "    min_df=2,  #setting min document frequency\n",
    "    max_features=5000, \n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "\n",
    "\n",
    "print(f'Shape of TF-IDF matrix: {X.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summing the terms over all documents, looping over them, adding them to a sorted list\n",
    "term_sums = X.sum(axis=0)\n",
    "term_freq = []\n",
    "\n",
    "for term, idx in vectorizer.vocabulary_.items():\n",
    "    term_freq.append((term, term_sums[0, idx]))\n",
    "\n",
    "term_freq = sorted(term_freq, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Amount of unique terms: \" + str(len(term_freq)))\n",
    "\n",
    "#plotting term frequencies to investigate the performance of the vectorizer\n",
    "frequencies = [freq for term, freq in term_freq]\n",
    "plt.hist(frequencies, bins=50)\n",
    "plt.xlabel('TF-IDF Score')\n",
    "plt.ylabel('Number of Terms')\n",
    "plt.title('Distribution of Term Frequencies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(model, sampling, data, dataframe):\n",
    "    \n",
    "    if model == \"Multinomial\":\n",
    "        model = MultinomialNB()\n",
    "    elif model == \"Bernoulli\":\n",
    "        model = BernoulliNB()\n",
    "    elif model == \"Complement\":\n",
    "        model = ComplementNB()\n",
    "    elif model == \"LogReg\":\n",
    "        model = LogisticRegression()\n",
    "    elif model == \"SVC\":\n",
    "        model = SVC()\n",
    "    elif model == \"LinearSVC\":\n",
    "        model = LinearSVC()\n",
    "    elif model == \"KNN\":\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model == \"RandomForest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model == \"DecTree\":\n",
    "        model = DecisionTreeClassifier()\n",
    "    \n",
    "    if sampling == \"SMOTE\":\n",
    "        sampling = SMOTE(random_state=42)\n",
    "    elif sampling == \"OverSampler\":\n",
    "        sampling = RandomOverSampler(random_state=42)\n",
    "        \n",
    "\n",
    "    #first split data into train+temporary, then train is split into train+validation.\n",
    "    df_train, df_temp = train_test_split(data, test_size=0.5, random_state=42)  \n",
    "    df_test, df_val = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "    text_data = df_train['cleaned_body'].tolist()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_df=0.95,\n",
    "        min_df=2,\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "        )\n",
    "\n",
    "    X_train = vectorizer.fit_transform(text_data)\n",
    "    y_train = df_train[\"stance comment\"]\n",
    "    \n",
    "    if sampling != \"no_sampling\":\n",
    "\n",
    "        X_train_resampled, y_train_resampled = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        cross_val_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=kf, scoring='f1_weighted')\n",
    "        \n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        cross_val_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='f1_weighted')\n",
    "        \n",
    "        model.fit(X_train, y_train)    \n",
    "        \n",
    "    X_test = vectorizer.transform(df_test['cleaned_body'].tolist())\n",
    "    y_test = df_test[\"stance comment\"]\n",
    "\n",
    "    X_val = vectorizer.transform(df_val['cleaned_body'].tolist())\n",
    "    y_val = df_val[\"stance comment\"]\n",
    "    \n",
    "\n",
    "\n",
    "    print(f'Mean Cross-Validation F1: {np.mean(cross_val_scores):.4f}')\n",
    "    print(f'Standard Deviation of Cross-Validation F1: {np.std(cross_val_scores):.4f}')\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #add the unseen data script to this function comment if you want to do something else\n",
    "    unseen_predictions = model.predict(X_val)\n",
    "    \n",
    "    #print accuracy and classification report\n",
    "    print(\"Test score: \")\n",
    "    print(f\"{str(model)} Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"{str(model)} F1: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"Validation score: \")\n",
    "    print(f\"{str(model)} Accuracy: {accuracy_score(y_val, unseen_predictions)}\")\n",
    "    print(f\"{str(model)} F1: {f1_score(y_val, unseen_predictions, average='weighted')}\")\n",
    "    print(classification_report(y_val, unseen_predictions))\n",
    "\n",
    "\n",
    "    #store the results in the dataframe\n",
    "    df_models_combine = {\n",
    "        'Model name': model,\n",
    "        'Sampling technique': sampling,\n",
    "        'Test accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'Test F1': round(f1_score(y_test, y_pred, average='weighted'), 4),\n",
    "        'Validation accuracy': round(accuracy_score(y_val, unseen_predictions), 4),\n",
    "        'Validation F1': round(f1_score(y_val, unseen_predictions, average='weighted'), 4)\n",
    "    }\n",
    "\n",
    "    dataframe = dataframe.append(df_models_combine, ignore_index=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pd.DataFrame()\n",
    "\n",
    "outputresult = classification(\"Complement\", \"no_sampling\", df_related_binary, outputdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"Multinomial\",\"Bernoulli\",\"Complement\",\"LogReg\",\"SVC\",\"LinearSVC\",\"KNN\",\"RandomForest\",\"DecTree\"]\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for i in model_list:\n",
    "    result_df = classification(i, \"no_sampling\", df_related, result_df)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel(\"results/classificationscores3classes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-jordan",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_binary[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbs[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related[\"stance comment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data = df_related #change if needed\n",
    "\n",
    "df_train, df_temp = train_test_split(nn_data, test_size=0.5, random_state=42)  \n",
    "df_test, df_val = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#df_train, df_test = train_test_split(nn_data, test_size=0.35, random_state=42)  \n",
    "\n",
    "y = nn_data[\"stance comment\"]\n",
    "\n",
    "text_data = df_train['cleaned_body'].tolist()\n",
    "    \n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "X_train = vectorizer.fit_transform(text_data)\n",
    "y_train = df_train[\"stance comment\"]\n",
    "\n",
    "X_test = vectorizer.transform(df_test['cleaned_body'].tolist())\n",
    "y_test = df_test[\"stance comment\"]\n",
    "\n",
    "X_val = vectorizer.transform(df_val['cleaned_body'].tolist())\n",
    "y_val = df_val[\"stance comment\"]\n",
    "\n",
    "#sampling = RandomOverSampler(random_state=42)\n",
    "#sampling = SMOTE(random_state=42)\n",
    "sampling = \"no_sampling\"\n",
    "\n",
    "#X_train_resampled, y_train_resampled = sampling.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "#y_train_encoded = label_encoder.fit_transform(y_train_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "#convert data to torch tensors\n",
    "#X_train_tensor = torch.tensor(X_train_resampled.toarray(), dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val.toarray(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "#mapping labels for easy understanding\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS ONE FOR MULTICLASS DATA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = len(y.unique())\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Test Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    print(f'Test Set F1 Score (weighted): {test_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))    \n",
    "    \n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in val_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    y_pred_val = []\n",
    "    y_true_val = []\n",
    "\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred_val.extend(predicted.cpu().numpy())\n",
    "        y_true_val.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(str(sampling))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "    print(f'Validation Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    print(f'Validation Set F1 Score (weighted): {val_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS ONE FOR MULTICLASS DATA WITH CLASS WEIGHT\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = len(y.unique())\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "#loss function with class weights\n",
    "class_counts = y.value_counts().sort_index().tolist() \n",
    "class_weights = [sum(class_counts) / count for count in class_counts]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Test Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    print(f'Test Set F1 Score (weighted): {test_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))    \n",
    "    \n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for texts, labels in val_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    y_pred_val = []\n",
    "    y_true_val = []\n",
    "\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred_val.extend(predicted.cpu().numpy())\n",
    "        y_true_val.extend(labels.cpu().numpy())\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    print(str(sampling))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    val_f1_score = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "    print(f'Validation Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    print(f'Validation Set F1 Score (weighted): {val_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINARY CLASSIFICATION WITH CLASS WEIGHTS\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = 1  \n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "#trying to avoid the model being biased towards majority class by adjusting weights\n",
    "class_weights = torch.tensor([len(y) / y.value_counts()[0], len(y) / y.value_counts()[1]], dtype=torch.float).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()  #make labels float for BCEWithLogitsLoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts).squeeze()  \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()\n",
    "        outputs = model(texts).squeeze()\n",
    "        predictions = torch.round(torch.sigmoid(outputs))  #sigmoid for binary classification\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(f'Test Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    test_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Test Set F1 Score (weighted): {test_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for texts, labels in val_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()\n",
    "        outputs = model(texts).squeeze()\n",
    "        predictions = torch.round(torch.sigmoid(outputs))  #sigmoid for binary classification\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "       \n",
    "    print(\"\\n\")\n",
    "    print(str(sampling))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(f'Validation Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    val_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Validation Set F1 Score (weighted): {val_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINARY CLASSIFICATION WITHOUT CLASS WEIGHTS\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = 1  #binary classification\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()  #make labels float for BCEWithLogitsLoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for texts, labels in test_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()\n",
    "        outputs = model(texts).squeeze()\n",
    "        predictions = torch.round(torch.sigmoid(outputs))  #sigmoid for binary classification\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(f'Test Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    test_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Test Set F1 Score (weighted): {test_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for texts, labels in val_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()\n",
    "        outputs = model(texts).squeeze()\n",
    "        predictions = torch.round(torch.sigmoid(outputs))  #sigmoid for binary classification\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "       \n",
    "    print(\"\\n\")\n",
    "    print(str(sampling))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(f'Validation Set Accuracy: {100 * correct / total:.2f}%')\n",
    "    val_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f'Validation Set F1 Score (weighted): {val_f1_score:.2f}')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
